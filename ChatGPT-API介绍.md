- `model`（必填）：要使用的OpenAI模型的ID。您可以使用“List models”API来查看所有可用的模型，或查看我们的“Model overview”页面了解这些模型的描述。
- `prompt`（可选）：要为其生成完成的提示字符串。可以使用字符串、字符串数组、令牌数组或令牌数组的数组表示。如果未指定提示，则模型将生成一个新文档的开头。
- `suffix`（可选）：插入文本的完成之后遵循的后缀。默认值为null。
- `max_tokens`（可选）：在完成中生成的最大令牌数。默认值为16。
- `temperature`（可选）：使用的采样温度。范围为0到2，其中数字越大，生成的输出越随机；数字越小，生成的输出越确定性。
- `top_p`（可选）：采用“Nucleus Sampling”中的概率阈值，只有概率质量占前N(%）的词才有可能被输出。类似`temperature`参数，是一种控制输出随机性和顶着意向性的一种方式。
- `n`（可选）：要为每个提示生成的完成次数。请注意，此参数生成的完成次数较多，会快速消耗您的API调用次数。
- `stream`（可选）：是否回传批量异步请求状态的进展。如果设置，则服务器将“已完成”的消息作为数据流传递回来。
- `logprobs`（可选）：将生成完成的每个可选单词的对数概率包含在响应中。默认值为null。
- `echo`（可选）：是否将需要完成的提示字符串在API的响应中一并返回。
- `stop`（可选）：一个字符串或字符串数组，其一组子字符串用于指定生成输出的停止点。适用于完成生成之后在指定位置停止。例如，您可以定义“\n”以在第一个换行符处停止。
- `presence_penalty`（可选）：浮点数，在-2和2之间，正值将惩罚新插入文本的概率，使其更难出现，而负值则强制控制更高的新插入概率。
- `frequency_penalty`（可选）：浮点数，在-2和2之间，正值将惩罚在当前提示已经出现过的单词的概率，负值则增加插入的概率。
- `best_of`（可选）：用于控制最后的输出结果，从服务器端中选择一个数量较大的完成实例，返回最优的一个，并可以具有更高的语义性。
- `logit_bias`（可选）：使用token ID对完成文本进行偏置控制，以限定特定建议语义单词的生成概率，可提高生成效率。
